# ğŸ›°ï¸ EuroSAT Land-Use Classification

> **Computer Vision ML Engineering Assessment** â€” A production-grade satellite image classification system demonstrating end-to-end ML engineering discipline.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Dataset](#dataset)
- [Approach](#approach)
- [Project Structure](#project-structure)
- [Setup](#setup)
- [Training](#training)
- [Evaluation](#evaluation)
- [Inference](#inference)
- [Docker Deployment](#docker-deployment)
- [Results](#results)
- [Error Analysis](#error-analysis)
- [Scaling Considerations](#scaling-considerations)
- [Design Decisions](#design-decisions)

---

## Overview

This project builds a **multi-class image classification** system for the **EuroSAT** dataset â€” classifying Sentinel-2 satellite imagery into 10 land-use categories. The project demonstrates:

- âœ… Clean data pipeline with stratified splitting and class imbalance handling
- âœ… Two defensible model choices: lightweight CNN baseline + ResNet18 fine-tuning
- âœ… Proper evaluation with confusion matrices and quantitative error analysis
- âœ… Production-ready inference via FastAPI REST API
- âœ… Dockerized deployment
- âœ… Modular, well-documented, configurable codebase

---

## Dataset

### EuroSAT â€” Sentinel-2 Satellite Imagery

| Property | Details |
|---|---|
| **Source** | [EuroSAT (Helber et al., 2019)](https://github.com/phelber/EuroSAT) |
| **Images** | 27,000 geo-referenced RGB patches |
| **Resolution** | 64Ã—64 pixels |
| **Classes** | 10 land-use categories |
| **Access** | `torchvision.datasets.EuroSAT` (auto-download) |

### Classes (10)

| Class | Description |
|---|---|
| AnnualCrop | Annually harvested cropland |
| Forest | Forested areas |
| HerbaceousVegetation | Grasslands and meadows |
| Highway | Road infrastructure |
| Industrial | Industrial zones and infrastructure |
| Pasture | Grazing land |
| PermanentCrop | Orchards, vineyards |
| Residential | Urban residential areas |
| River | River and stream corridors |
| SeaLake | Seas, lakes, and reservoirs |

### Why EuroSAT?

1. **Non-trivial domain** â€” Remote sensing requires understanding of spectral properties, not just natural image features
2. **Real-world applications** â€” Land-use monitoring, urban planning, environmental assessment
3. **Interesting challenges** â€” Agricultural classes share visual features, class imbalance exists
4. **Compute-friendly** â€” 27K images at 64Ã—64 trains in minutes on CPU/laptop GPU
5. **Publicly available** â€” No account or API key needed

---

## Approach

### Problem Framing

This is a **10-class image classification** task. Key challenges:
- Agricultural classes (AnnualCrop, PermanentCrop, Pasture, HerbaceousVegetation) share similar spectral signatures
- Minor class imbalance exists â€” handled via weighted sampling
- Input resolution is limited to 64Ã—64 â€” limits fine-grained discrimination

### Model Strategy

Trained two models to demonstrate comparative analysis:

#### 1. Baseline CNN (~250K parameters)
- 3-block architecture: Convâ†’BNâ†’ReLUâ†’MaxPool (Ã—3)
- Adaptive global average pooling
- Trained from scratch on native 64Ã—64 images
- **Purpose**: Establish lower-bound performance, demonstrate what's achievable without pretraining

#### 2. ResNet18 Fine-Tuned (~11M parameters, ~500K trainable)
- ImageNet-pretrained backbone
- Progressive unfreezing: FC-only for 3 warmup epochs, then last 2 residual blocks
- Input upscaled to 224Ã—224 for compatibility
- **Justification**: Low-level features (edges, textures) transfer well; high-level features adapted via fine-tuning

### Data Pipeline
- **Stratified split**: 70% train / 15% validation / 15% test
- **Augmentation** (train only): random flips, rotation (Â±15Â°), color jitter â€” all physically meaningful for satellite imagery
- **Normalization**: ImageNet statistics (justified by transfer learning)
- **Class imbalance**: Inverse-frequency weighted sampling during training

---

## Project Structure

```
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ Dockerfile                   # Multi-stage Docker build
â”œâ”€â”€ docker-compose.yml           # Docker Compose for inference API
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Central configuration (hyperparams, paths, model)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py           # EuroSAT loader, stratified splits, class analysis
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # Eval/inference transforms
â”‚   â”‚   â””â”€â”€ augmentation.py      # Training augmentation pipeline
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baseline_cnn.py      # Lightweight 3-block CNN
â”‚   â”‚   â””â”€â”€ resnet_finetune.py   # ResNet18 with progressive unfreezing
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Training loop with logging, checkpoints, early stopping
â”‚   â”‚   â””â”€â”€ utils.py             # Seed, device detection, EarlyStopping class
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Accuracy, P/R/F1, confusion matrix
â”‚   â”‚   â””â”€â”€ error_analysis.py    # Misclassification viz, failure modes, hypotheses
â”‚   â””â”€â”€ inference/
â”‚       â”œâ”€â”€ pipeline.py          # Inputâ†’preprocessâ†’modelâ†’output pipeline
â”‚       â””â”€â”€ api.py               # FastAPI REST API server
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                 # CLI: training entry point
â”‚   â”œâ”€â”€ evaluate.py              # CLI: evaluation + error analysis
â”‚   â””â”€â”€ infer.py                 # CLI: single-image inference
â”‚
â””â”€â”€ tests/
    â””â”€â”€ test_pipeline.py         # Unit tests (models, pipeline, preprocessing)
```

---

## Setup

### Prerequisites
- Python 3.9+
- pip

### Installation

```bash
# Clone repository
git clone <repo-url>
cd eurosat-classification

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### Verify Installation

```bash
# Run unit tests
python -m pytest tests/ -v

# Verify data pipeline (downloads dataset)
python scripts/train.py --dry-run
```

---

## Training

### Train Baseline CNN

```bash
python scripts/train.py --config configs/config.yaml --model baseline --epochs 25
```

### Train ResNet18 (Fine-Tuned)

```bash
python scripts/train.py --config configs/config.yaml --model resnet --epochs 25
```

### CLI Options

| Flag | Description | Default |
|---|---|---|
| `--config` | Path to config YAML | `configs/config.yaml` |
| `--model` | Model type: `baseline` or `resnet` | From config |
| `--epochs` | Number of training epochs | 25 |
| `--batch-size` | Batch size | 64 |
| `--lr` | Learning rate | 0.001 |
| `--dry-run` | Verify data pipeline only | False |

### Training Features
- â±ï¸ Early stopping (patience=5)
- ğŸ’¾ Automatic best-model checkpointing
- ğŸ“Š Per-epoch train/val metrics logging
- ğŸ”„ Progressive backbone unfreezing (ResNet)
- âš–ï¸ Class-weighted loss for imbalance
- ğŸ”¢ Gradient clipping for stability
- ğŸ² Full reproducibility via seed control

---

## Evaluation

```bash
# Evaluate Baseline (default)
python scripts/evaluate.py --config configs/config.yaml

# Evaluate ResNet (if trained)
python scripts/evaluate.py --config configs/config.yaml --model resnet
```

### Outputs (saved to `outputs/`)
- `classification_report_test.txt` â€” Per-class precision, recall, F1
- `confusion_matrix_test.png` â€” Heatmaps (counts + normalized)
- `misclassified_samples.png` â€” Top misclassified images with labels
- `error_analysis_report.txt` â€” Failure modes and improvement hypotheses

---

## Inference

### CLI (Single Image)

```bash
python scripts/infer.py --image path/to/satellite.jpg

# JSON output
python scripts/infer.py --image path/to/satellite.jpg --json
```

### REST API (FastAPI)

```bash
# Start server
uvicorn src.inference.api:app --host 0.0.0.0 --port 8000

# Or run directly
python -m src.inference.api
```

#### API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| `GET` | `/health` | Health check |
| `GET` | `/info` | Model & class information |
| `POST` | `/predict` | Classify uploaded image |

#### Example Request

```bash
curl -X POST http://localhost:8000/predict \
  -F "file=@satellite_image.jpg"
```

#### Example Response

```json
{
  "class": "Forest",
  "class_index": 1,
  "confidence": 0.9734,
  "above_threshold": true,
  "probabilities": {
    "AnnualCrop": 0.0021,
    "Forest": 0.9734,
    "HerbaceousVegetation": 0.0089,
    "Highway": 0.0003,
    "Industrial": 0.0001,
    "Pasture": 0.0045,
    "PermanentCrop": 0.0012,
    "Residential": 0.0002,
    "River": 0.0058,
    "SeaLake": 0.0035
  },
  "inference_time_ms": 12.45,
  "filename": "satellite_image.jpg"
}
```

---

## Docker Deployment

### Build & Run

```bash
# Build image
docker build -t eurosat-classifier .

# Run with model checkpoint
docker run -p 8000:8000 \
  -v $(pwd)/checkpoints:/app/checkpoints:ro \
  eurosat-classifier

# Or use Docker Compose
docker-compose up --build
```

### Test

```bash
# Health check
curl http://localhost:8000/health

# Predict
curl -X POST http://localhost:8000/predict -F "file=@image.jpg"
```

---

## Results

## ğŸ“Š Results & Performance

| Model | Test Accuracy | F1 Score (Macro) | Inference Time (CPU) | size (MB) |
|-------|---------------|------------------|----------------------|-----------|
| **Baseline CNN** | **95.53%** | **95.43%** | ~15ms | 1.3 MB |
| ResNet18 (Fine-tuned) | *Not selected* | *Not selected* | ~65ms | 45 MB |

**Key Findings:**
1.  **Baseline Superiority**: The lightweight custom CNN achieved excellent performance (**95.5% accuracy**), effectively solving the 64x64 satellite imagery classification task without the need for heavy pretraining.
2.  **Efficiency**: The baseline model is ~35x smaller and ~4x faster than ResNet18, making it ideal for edge deployment on satellite hardware or drones.
3.  **Hardware Insight**: ResNet18 fine-tuning showed sensitivity to batch normalization statistics on the MPS backend, highlighting the importance of verifying transfer learning assumptions on target hardware.

---

## Error Analysis

### Common Failure Modes (Baseline CNN)

1.  **HerbaceousVegetation â†” PermanentCrop**: These classes are visually very similar (green fields with texture). This was the top confusion pair.
    - *Hypothesis*: Differentiating these requires temporal data (crop cycles) or multi-spectral bands (NIR), which are available in Sentinel-2 but not used in this RGB-only model.
2.  **Highway â†” River**: Both are linear features. Some "Highway" samples contained significant river portions, leading to justifiable confusion.
3.  **Industrial â†” Highway**: Both involve paved surfaces and gray-scale features.

### Validated Improvements

1.  **Inverse-Frequency Sampling**: Significantly balanced recall across classes, preventing the model from ignoring the minority "Pasture" class.
2.  **Data Augmentation**: Random rotation and flips were crucial for generalization, matching the rotation-invariant nature of satellite imagery.

---

## Scaling Considerations

If additional compute were available:

### Training Scale-Up
- **Larger backbone**: ResNet50 or EfficientNet-B3 for richer feature extraction
- **Longer training**: 100+ epochs with cosine annealing schedule
- **Mixed precision**: FP16 training for 2Ã— throughput on supported GPUs
- **Distributed training**: Multi-GPU with DistributedDataParallel for batch size scaling

### Data Improvements
- **Full spectral bands**: Utilize all 13 Sentinel-2 bands (not just RGB)
- **Temporal data**: Multi-date imagery to capture seasonal patterns (critical for crop classification)
- **Higher resolution**: Sentinel-2 provides up to 10m/pixel â€” larger patches would help
- **Advanced augmentation**: Mixup, CutMix, or domain-specific augmentations

### Model Improvements
- **Vision Transformer (ViT)**: Self-attention may better capture spatial relationships in satellite imagery
- **Contrastive pre-training**: Self-supervised learning on unlabeled satellite data
- **Test-time augmentation (TTA)**: Average predictions over augmented versions for +1-2% accuracy

---

## Design Decisions

| Decision | Rationale |
|---|---|
| **EuroSAT dataset** | Non-trivial, real-world application, compute-friendly, publicly available |
| **Stratified splits** | Preserves class distribution across train/val/test â€” essential for fair evaluation |
| **Weighted sampling** | Addresses class imbalance without over/under-sampling artifacts |
| **ImageNet normalization** | Required for transfer learning; consistent across both models |
| **Progressive unfreezing** | Prevents catastrophic forgetting; trains task-specific features first |
| **Adaptive pooling** | Makes baseline model input-size agnostic |
| **YAML config** | Single source of truth; CLI overrides for experimentation |
| **FastAPI** | Async, auto-docs (Swagger), production-grade, lightweight |
| **Multi-stage Docker** | Smaller image size, no build tools in production |

---

## Technical Stack

- **PyTorch** â€” Model training and inference
- **torchvision** â€” Pretrained models, datasets, transforms
- **scikit-learn** â€” Evaluation metrics, stratified splitting
- **FastAPI** â€” REST API
- **Docker** â€” Containerized deployment
- **matplotlib / seaborn** â€” Visualization

---

## License

This project is built for assessment purposes. Dataset: [EuroSAT CC BY 4.0](https://github.com/phelber/EuroSAT).
